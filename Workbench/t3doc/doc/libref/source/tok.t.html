<html><head><link rel=stylesheet type="text/css" href="../libref.css"><title>tok.t</title></head><body>
<table class=ban><tr><td><h1>tok.t</h1><td align=right><a href="../file/tok.t.html">documentation</a></table><pre>
<a name="1"></a>#charset "us-ascii"
<a name="2"></a>
<a name="3"></a>/*
<a name="4"></a> *   Tokenizer - customizable tokenizer class for use with the intrinsic
<a name="5"></a> *   class 'grammar-production' parser.
<a name="6"></a> *   
<a name="7"></a> *   This tokenizer implementation is parameterized with a set of rules
<a name="8"></a> *   (see below); a basic set of rules is provided, but users can
<a name="9"></a> *   customize the tokenizer quite extensively simply by subclassing the
<a name="10"></a> *   Tokenizer class and overriding the 'rules_' property with a new set
<a name="11"></a> *   of rules declarations.  
<a name="12"></a> */
<a name="13"></a>
<a name="14"></a>#include "tads.h"
<a name="15"></a>#include "t3.h"
<a name="16"></a>#include "dict.h"
<a name="17"></a>#include "tok.h"
<a name="18"></a>#include "vector.h"
<a name="19"></a>
<a name="20"></a>/* ------------------------------------------------------------------------ */
<a name="21"></a>/*
<a name="22"></a> *   Tokenizer exceptions 
<a name="23"></a> */
<a name="24"></a>
<a name="25"></a>/*
<a name="26"></a> *   base class for all tokenizer errors (to allow blanket 'catch') 
<a name="27"></a> */
<a name="28"></a>class TokenizerError: Exception;
<a name="29"></a>
<a name="30"></a>/*
<a name="31"></a> *   no match for token 
<a name="32"></a> */
<a name="33"></a>class TokErrorNoMatch: TokenizerError
<a name="34"></a>    construct(str)
<a name="35"></a>    {
<a name="36"></a>        /* remember the full remaining text */
<a name="37"></a>        remainingStr_ = str;
<a name="38"></a>
<a name="39"></a>        /* 
<a name="40"></a>         *   for convenience, separately remember the single character
<a name="41"></a>         *   that we don't recognize - this is simply the first character
<a name="42"></a>         *   of the rest of the line 
<a name="43"></a>         */
<a name="44"></a>        curChar_ = str.substr(1, 1);
<a name="45"></a>    }
<a name="46"></a>
<a name="47"></a>    /* 
<a name="48"></a>     *   The remainder of the string.  This is the part that couldn't be
<a name="49"></a>     *   matched; we were successful in matching up to this point. 
<a name="50"></a>     */
<a name="51"></a>    remainingStr_ = nil
<a name="52"></a>
<a name="53"></a>    /* current character (first character of remainingStr_) */
<a name="54"></a>    curChar_ = nil
<a name="55"></a>;
<a name="56"></a>
<a name="57"></a>/* ------------------------------------------------------------------------ */
<a name="58"></a>/*
<a name="59"></a> *   Basic token types
<a name="60"></a> */
<a name="61"></a>
<a name="62"></a>/* word */
<a name="63"></a>enum token tokWord;
<a name="64"></a>
<a name="65"></a>/* quoted string */
<a name="66"></a>enum token tokString;
<a name="67"></a>
<a name="68"></a>/* punctuation */
<a name="69"></a>enum token tokPunct;
<a name="70"></a>
<a name="71"></a>/* integer number */
<a name="72"></a>enum token tokInt;
<a name="73"></a>
<a name="74"></a>
<a name="75"></a>/* ------------------------------------------------------------------------ */
<a name="76"></a>/*
<a name="77"></a> *   Tokenizer base class
<a name="78"></a> */
<a name="79"></a>class Tokenizer: object
<a name="80"></a>    /*
<a name="81"></a>     *   Tokenizing rules.  The subclass can override this to specify a
<a name="82"></a>     *   list that defines different tokenization rules.  Each entry in the
<a name="83"></a>     *   master rules_ list is one rule.  Each rule is a list consisting of
<a name="84"></a>     *   the name of the rule; the pattern to match for the rule; the token
<a name="85"></a>     *   type (an 'enum token') to use when the rule is matched; the value
<a name="86"></a>     *   computation rule; and the value test rule.
<a name="87"></a>     *   
<a name="88"></a>     *   The name of a rule is just an arbitrary string to identify the
<a name="89"></a>     *   rule.  This can be used to insert new rules in order relative to
<a name="90"></a>     *   known existing rules, or to delete known existing rules.
<a name="91"></a>     *   
<a name="92"></a>     *   If the value computation rule is nil, we'll just use the matching
<a name="93"></a>     *   text as the token value.  If the value rule is a string, we'll use
<a name="94"></a>     *   the string as a replacement pattern (with rexReplace).  If it's a
<a name="95"></a>     *   property ID, we'll invoke the property of self with the following
<a name="96"></a>     *   arguments:
<a name="97"></a>     *   
<a name="98"></a>     *   txt, typ, toks
<a name="99"></a>     *   
<a name="100"></a>     *   'txt' is the matched text; 'typ' is the token type from the rule;
<a name="101"></a>     *   and 'toks' is a vector to which the new token or tokens are to be
<a name="102"></a>     *   added.  The routine is responsible for adding the appropriate
<a name="103"></a>     *   values to the result list.  Note that the routine can add more
<a name="104"></a>     *   than one token to the results if desired.
<a name="105"></a>     *   
<a name="106"></a>     *   If the value test rule is non-nil, it must be either a method or a
<a name="107"></a>     *   function; we'll call the method or function to test to see if the
<a name="108"></a>     *   matched value is valid.  We'll call the method (on self) with the
<a name="109"></a>     *   matching text as the argument; if the method returns true, the
<a name="110"></a>     *   rule matches, otherwise the rule fails, and we'll continue looking
<a name="111"></a>     *   for another rule as though we hadn't matched the rule's regular
<a name="112"></a>     *   expression in the first place.  This can be used for rules that
<a name="113"></a>     *   require more than a simple regular expression match; for example,
<a name="114"></a>     *   the value test can be used to look up the match in a dictionary,
<a name="115"></a>     *   so that the rule only matches tokens that are defined in the
<a name="116"></a>     *   dictionary.  
<a name="117"></a>     */
<a name="118"></a>    rules_ = static
<a name="119"></a>    [
<a name="120"></a>        /* skip whitespace */
<a name="121"></a>        ['whitespace', new RexPattern('&lt;Space&gt;+'), nil, &amp;tokCvtSkip, nil],
<a name="122"></a>
<a name="123"></a>        /* certain punctuation marks */
<a name="124"></a>        ['punctuation', new RexPattern('[.,;:?!]'), tokPunct, nil, nil],
<a name="125"></a>
<a name="126"></a>        /* 
<a name="127"></a>         *   Words - note that we convert everything to lower-case.  A
<a name="128"></a>         *   word must start with an alphabetic character, but can contain
<a name="129"></a>         *   alphabetics, digits, hyphens, and apostrophes after that. 
<a name="130"></a>         */
<a name="131"></a>        ['word', new RexPattern('&lt;Alpha&gt;(&lt;AlphaNum&gt;|[-\'])*'),
<a name="132"></a>         tokWord, &amp;tokCvtLower, nil],
<a name="133"></a>
<a name="134"></a>        /* strings */
<a name="135"></a>        ['string single-quote',
<a name="136"></a>         new RexPattern('\'(.*)\''), tokString, nil, nil],
<a name="137"></a>        ['string double-quote',
<a name="138"></a>         new RexPattern('"(.*)"'), tokString, nil, nil],
<a name="139"></a>
<a name="140"></a>        /* integer numbers */
<a name="141"></a>        ['integer', new RexPattern('[0-9]+'), tokInt, nil, nil]
<a name="142"></a>    ]
<a name="143"></a>
<a name="144"></a>    /*
<a name="145"></a>     *   Insert a new rule before or after the existing rule with the name
<a name="146"></a>     *   'curName'.  If 'curName' is nil, or rule is found with the given
<a name="147"></a>     *   name, we'll insert the new rule at the end of the list.  'rule'
<a name="148"></a>     *   must be a list with the standard elements for a tokenizer rule.
<a name="149"></a>     *   'after' is nil to insert the new rule before the given existing
<a name="150"></a>     *   rule, true to insert after it.  
<a name="151"></a>     */
<a name="152"></a>    insertRule(rule, curName, after)
<a name="153"></a>    {
<a name="154"></a>        local idx;
<a name="155"></a>
<a name="156"></a>        /* 
<a name="157"></a>         *   if the name of an existing rule was supplied, find the
<a name="158"></a>         *   existing rule with the given name 
<a name="159"></a>         */
<a name="160"></a>        idx = nil;
<a name="161"></a>        if (curName != nil)
<a name="162"></a>            idx = rules_.indexWhich({x: tokRuleName(x) == curName});
<a name="163"></a>
<a name="164"></a>        /* if we didn't find curName, insert at the end of the list */
<a name="165"></a>        if (idx == nil)
<a name="166"></a>            idx = rules_.length();
<a name="167"></a>
<a name="168"></a>        /* if we're inserting after the given element, adjust the index */
<a name="169"></a>        if (after)
<a name="170"></a>            ++idx;
<a name="171"></a>
<a name="172"></a>        /* insert the new rule */
<a name="173"></a>        insertRuleAt(rule, idx);
<a name="174"></a>    }
<a name="175"></a>
<a name="176"></a>    /* 
<a name="177"></a>     *   Insert a rule at the given index in our rules list.  'rule' must
<a name="178"></a>     *   be a list with the standard elements for a tokenizer rule.  'idx'
<a name="179"></a>     *   is the index of the new rule; we'll insert before the existing
<a name="180"></a>     *   element at this index; so if 'idx' is 1, we'll insert before the
<a name="181"></a>     *   first existing rule.  
<a name="182"></a>     */
<a name="183"></a>    insertRuleAt(rule, idx)
<a name="184"></a>    {
<a name="185"></a>        /* insert the rule */
<a name="186"></a>        rules_ = rules_.insertAt(idx, rule);
<a name="187"></a>    }
<a name="188"></a>
<a name="189"></a>    /*
<a name="190"></a>     *   Delete a rule by name.  This finds the rule with the given name
<a name="191"></a>     *   and removes it from the list. 
<a name="192"></a>     */
<a name="193"></a>    deleteRule(name)
<a name="194"></a>    {
<a name="195"></a>        local idx;
<a name="196"></a>        
<a name="197"></a>        /* find the rule with the given name */
<a name="198"></a>        idx = rules_.indexWhich({x: tokRuleName(x) == name});
<a name="199"></a>
<a name="200"></a>        /* if we found the named element, remove it from the list */
<a name="201"></a>        if (idx != nil)
<a name="202"></a>            deleteRuleAt(idx);
<a name="203"></a>    }
<a name="204"></a>
<a name="205"></a>    /* delete the rule at the given index */
<a name="206"></a>    deleteRuleAt(idx)
<a name="207"></a>    {
<a name="208"></a>        /* delete the rule */
<a name="209"></a>        rules_ = rules_.removeElementAt(idx);
<a name="210"></a>    }
<a name="211"></a>
<a name="212"></a>    /* convert a string to lower-case (for value computation rules) */
<a name="213"></a>    tokCvtLower(txt, typ, toks)
<a name="214"></a>    {
<a name="215"></a>        /* add the lower-cased version of the string to the result list */
<a name="216"></a>        toks.append([txt.toLower(), typ, txt]);
<a name="217"></a>    }
<a name="218"></a>
<a name="219"></a>    /* 
<a name="220"></a>     *   processing routine to skip a match - this is used for whitespace
<a name="221"></a>     *   and other text that does not result in any tokens in the result
<a name="222"></a>     *   list 
<a name="223"></a>     */
<a name="224"></a>    tokCvtSkip(txt, typ, toks)
<a name="225"></a>    {
<a name="226"></a>        /* simply skip the text without generating any new tokens */
<a name="227"></a>    }
<a name="228"></a>
<a name="229"></a>    /*
<a name="230"></a>     *   Tokenize a string.  If we find text that we can't match to any of
<a name="231"></a>     *   the rules, we'll throw an exception (TokErrorNoMatch).  If we
<a name="232"></a>     *   succeed in tokenizing the entire string, we'll return a list with
<a name="233"></a>     *   one element per token.  Each element of the main list is a
<a name="234"></a>     *   sublist with the following elements describing a token:
<a name="235"></a>     *   
<a name="236"></a>     *   - The first element gives the token's value.
<a name="237"></a>     *   
<a name="238"></a>     *   - The second element the token type (given as a token type enum
<a name="239"></a>     *   value).
<a name="240"></a>     *   
<a name="241"></a>     *   - The third element the original token strings, before any
<a name="242"></a>     *   conversions or evaluations were performed.  For example, this
<a name="243"></a>     *   maintains the original case of strings that are lower-cased for
<a name="244"></a>     *   the corresponding token values.
<a name="245"></a>     */
<a name="246"></a>    tokenize(str)
<a name="247"></a>    {
<a name="248"></a>        local toks = new Vector(32);
<a name="249"></a>        local startIdx = 1;
<a name="250"></a>        local len = str.length();
<a name="251"></a>        
<a name="252"></a>        /* keep going until we run out of string */
<a name="253"></a>    mainLoop:
<a name="254"></a>        while (startIdx &lt;= len)
<a name="255"></a>        {
<a name="256"></a>            /* run through the rules in sequence until we match one */
<a name="257"></a>        ruleLoop:
<a name="258"></a>            for (local i = 1, local cnt = rules_.length() ; i &lt;= cnt ; ++i)
<a name="259"></a>            {
<a name="260"></a>                local cur;
<a name="261"></a>                local match;
<a name="262"></a>                local val;
<a name="263"></a>                        
<a name="264"></a>                /* get the current rule */
<a name="265"></a>                cur = rules_[i];
<a name="266"></a>
<a name="267"></a>                /* check for a match to the rule's pattern */
<a name="268"></a>                match = rexMatch(tokRulePat(cur), str, startIdx);
<a name="269"></a>                if (match != nil &amp;&amp; match &gt; 0)
<a name="270"></a>                {
<a name="271"></a>                    local test;
<a name="272"></a>                    local txt;
<a name="273"></a>                    local typ;
<a name="274"></a>
<a name="275"></a>                    /* get the matching text */
<a name="276"></a>                    txt = str.substr(startIdx, match);
<a name="277"></a>
<a name="278"></a>                    /* 
<a name="279"></a>                     *   if there's a value test, invoke it to determine
<a name="280"></a>                     *   if the token really matches 
<a name="281"></a>                     */
<a name="282"></a>                    if ((test = tokRuleTest(cur)) != nil)
<a name="283"></a>                    {
<a name="284"></a>                        local accept;
<a name="285"></a>
<a name="286"></a>                        /* check what kind of test function we have */
<a name="287"></a>                        switch (dataType(test))
<a name="288"></a>                        {
<a name="289"></a>                        case TypeFuncPtr:
<a name="290"></a>                        case TypeObject:
<a name="291"></a>                            /* it's a function or anonymous function */
<a name="292"></a>                            accept = (test)(txt);
<a name="293"></a>                            break;
<a name="294"></a>
<a name="295"></a>                        case TypeProp:
<a name="296"></a>                            /* it's a method */
<a name="297"></a>                            accept = self.(test)(txt);
<a name="298"></a>                            break;
<a name="299"></a>
<a name="300"></a>                        default:
<a name="301"></a>                            /* consider anything else to be accepted */
<a name="302"></a>                            accept = true;
<a name="303"></a>                            break;
<a name="304"></a>                        }
<a name="305"></a>
<a name="306"></a>                        /* 
<a name="307"></a>                         *   if the value test failed, it means that the
<a name="308"></a>                         *   token doesn't match this rule after all -
<a name="309"></a>                         *   ignore the regex match and keep searching for
<a name="310"></a>                         *   another rule 
<a name="311"></a>                         */
<a name="312"></a>                        if (!accept)
<a name="313"></a>                            continue ruleLoop;
<a name="314"></a>                    }
<a name="315"></a>
<a name="316"></a>                    /* get the type of the token from the rule */
<a name="317"></a>                    typ = tokRuleType(cur);
<a name="318"></a>                    
<a name="319"></a>                    /* get this value processing rule */
<a name="320"></a>                    val = tokRuleVal(cur);
<a name="321"></a>
<a name="322"></a>                    /* determine what value to use */
<a name="323"></a>                    switch(dataTypeXlat(val))
<a name="324"></a>                    {
<a name="325"></a>                    case TypeNil:
<a name="326"></a>                        /* use the matching text verbatim */
<a name="327"></a>                        toks.append([txt, typ, txt]);
<a name="328"></a>                        break;
<a name="329"></a>                        
<a name="330"></a>                    case TypeProp:
<a name="331"></a>                        /* 
<a name="332"></a>                         *   invoke the property - it's responsible for
<a name="333"></a>                         *   adding the token or tokens to the results
<a name="334"></a>                         *   lists 
<a name="335"></a>                         */
<a name="336"></a>                        self.(val)(txt, typ, toks);
<a name="337"></a>                        break;
<a name="338"></a>                        
<a name="339"></a>                    case TypeSString:
<a name="340"></a>                        /* it's a regular expression replacement */
<a name="341"></a>                        toks.append(
<a name="342"></a>                            [rexReplace(tokRulePat(cur),
<a name="343"></a>                                        txt, val, ReplaceOnce),
<a name="344"></a>                             typ, txt]);
<a name="345"></a>                        break;
<a name="346"></a>
<a name="347"></a>                    case TypeFuncPtr:
<a name="348"></a>                        /* invoke the function */
<a name="349"></a>                        (val)(txt, typ, toks);
<a name="350"></a>                        break;
<a name="351"></a>
<a name="352"></a>                    default:
<a name="353"></a>                        /* 
<a name="354"></a>                         *   use any other value exactly as given in
<a name="355"></a>                         *   the rule 
<a name="356"></a>                         */
<a name="357"></a>                        toks.append([val, typ, txt]);
<a name="358"></a>                        break;
<a name="359"></a>                    }
<a name="360"></a>
<a name="361"></a>                    /* 
<a name="362"></a>                     *   continue the search at the next character after
<a name="363"></a>                     *   the end of this token 
<a name="364"></a>                     */
<a name="365"></a>                    startIdx += match;
<a name="366"></a>
<a name="367"></a>                    /* start over with the rest of the string */
<a name="368"></a>                    continue mainLoop;
<a name="369"></a>                }
<a name="370"></a>            }
<a name="371"></a>
<a name="372"></a>            /*
<a name="373"></a>             *   We failed to find a match for this part of the string.
<a name="374"></a>             *   Throw an exception and let the caller figure out what to
<a name="375"></a>             *   do.  The exception parameter gives the rest of the
<a name="376"></a>             *   string, so the caller can display a suitable error
<a name="377"></a>             *   message if desired.  
<a name="378"></a>             */
<a name="379"></a>            throw new TokErrorNoMatch(str.substr(startIdx));
<a name="380"></a>        }
<a name="381"></a>
<a name="382"></a>        /* we're done with the string - return out value and type lists */
<a name="383"></a>        return toks.toList();
<a name="384"></a>    }
<a name="385"></a>;
<a name="386"></a>
<a name="387"></a>/* ------------------------------------------------------------------------ */
<a name="388"></a>/*
<a name="389"></a> *   Test Section 
<a name="390"></a> */
<a name="391"></a>
<a name="392"></a>#ifdef TOK_TEST
<a name="393"></a>
<a name="394"></a>main(args)
<a name="395"></a>{
<a name="396"></a>    "Enter text to tokenize.  Type Q or QUIT when done. ";
<a name="397"></a>    for (;;)
<a name="398"></a>    {
<a name="399"></a>        local str, toks;
<a name="400"></a>
<a name="401"></a>        /* read a string */
<a name="402"></a>        "\b&gt;";
<a name="403"></a>        str = inputLine();
<a name="404"></a>
<a name="405"></a>        /* catch tokenization errors */
<a name="406"></a>        try
<a name="407"></a>        {
<a name="408"></a>            /* tokenize the string */
<a name="409"></a>            toks = Tokenizer.tokenize(str);
<a name="410"></a>
<a name="411"></a>            /* if the first token is 'quit', we're done */
<a name="412"></a>            if (toks.length() &gt; 0
<a name="413"></a>                &amp;&amp; getTokType(toks[1]) == tokWord
<a name="414"></a>                &amp;&amp; (getTokVal(toks[1])== 'quit' || getTokVal(toks[1]) == 'q'))
<a name="415"></a>            {
<a name="416"></a>                /* they want to stop - exit the command loop */
<a name="417"></a>                break;
<a name="418"></a>            }
<a name="419"></a>
<a name="420"></a>            /* display the tokens */
<a name="421"></a>            for (local i = 1, local cnt = toks.length() ; i &lt;= cnt ; ++i)
<a name="422"></a>                "(&lt;&lt;getTokVal(toks[i])&gt;&gt;) ";
<a name="423"></a>        }
<a name="424"></a>        catch (TokErrorNoMatch err)
<a name="425"></a>        {
<a name="426"></a>            "Unrecognized punctuation: &lt;&lt;err.remainingStr_.substr(1, 1)&gt;&gt;";
<a name="427"></a>        }
<a name="428"></a>    }
<a name="429"></a>}
<a name="430"></a>
<a name="431"></a>#endif /* TOK_TEST */
<a name="432"></a>
</pre>
<div class=ftr>TADS 3 Library Manual<br>Generated on 5/6/2009 from TADS version 3.0.18.1</div>
</body>
</html>
